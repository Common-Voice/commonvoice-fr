La séance est ouverte.
L’ordre du jour appelle la suite de la discussion du projet de loi relatif à la protection des données personnelles (numéros quatre cent quatre-vingt-dix, cinq cent quatre-vingt-douze, cinq cent soixante-dix-neuf).
Cet après-midi, l’Assemblée a poursuivi la discussion des articles, s’arrêtant à l’amendement numéro cent trente-quatre portant article additionnel après l’article treize.
La parole est à Madame Paula Forteza, rapporteure de la commission des lois constitutionnelles, de la législation et de l’administration générale de la République, pour soutenir l’amendement numéro cent trente-quatre.
Nous avons réfléchi à la façon de mieux protéger les données scolaires.
Par le présent amendement, nous proposons que les établissements d’enseignement à caractère scolaire mettent à la disposition du public, dans un format ouvert et aisément réutilisable, la liste des traitements automatisés de données à caractère personnel effectués sous leur responsabilité.
Ce dispositif répond à une demande particulière des parents d’élèves, qui voulaient savoir comment les données de leurs enfants étaient traitées par les établissements d’enseignement public.
La parole est à Madame la garde des sceaux, ministre de la justice, pour donner l’avis du Gouvernement.
Madame la rapporteure, la question que vous soulevez nous préoccupe évidemment tous : comment est encadré le traitement des données dans le milieu scolaire ? Ces données sont soumises aux dispositions du règlement général sur la protection des données – RGPD –, qui apporte de nombreuses garanties.
Plus largement, nous pouvons évidemment comprendre les préoccupations des parents d’élèves et du monde enseignant.
Le ministère de l’éducation nationale y est attentif et entend y répondre ; je peux vous assurer que le ministre lui-même y veille particulièrement.
C’est d’ailleurs une priorité de ce ministère, qui travaille au développement d’un certain nombre d’outils, avec la Commission nationale de l’informatique et des libertés – CNIL.
Une mission a été confiée en ce sens à l’Inspection générale de l’éducation nationale et à l’Inspection générale de l’administration de l’éducation nationale, le treize novembre deux mille dix-sept – il y a quelques mois.
Nous attendons les conclusions prochaines de cette mission.
Le ministère de l’éducation nationale déploie, en ce moment même, des efforts considérables pour mettre en œuvre le RGPD.
Celui-ci impose la tenue d’un registre par chaque responsable de traitement, c’est-à-dire pour l’essentiel par les chefs d’établissement.
Comme il existe de très nombreux établissements, l’éducation nationale procède aujourd’hui à un énorme travail de recensement, sous l’autorité des différents recteurs d’académie.
Ces registres seront une garantie fondamentale de la transparence des traitements.
Madame la rapporteure, c’est sans doute autour de ces registres que nous devons travailler, dans le sens que vous souhaitez.
Le Gouvernement a des réserves sur la rédaction de votre amendement.
Nous essayons de trouver une solution opérationnelle pour répondre aux préoccupations exprimées sur l’ensemble des bancs de cette assemblée.
La rédaction que vous proposez conduirait plus de cinquante-trois mille établissements à mettre à disposition du public, sans délai, la liste des traitements.
Or le ministère de l’éducation nationale considère, à juste titre, que rien ne permet de garantir que ces cinquante-trois mille établissements seront effectivement en mesure d’appliquer ces dispositions dans l’immédiat.
J’espère ainsi que nous pourrons trouver une solution qui vous convienne.
Dans cette attente, je vous demande de retirer votre amendement.
La parole est à Madame la rapporteure.
Je suis prête à attendre les conclusions des travaux du ministère de l’éducation nationale et à continuer à travailler pour pouvoir proposer le dispositif adéquat.
Je retire mon amendement.
Je suis saisie de trois amendements identiques, numéros quatre-vingt-dix rectifié, cent quarante-quatre rectifié et cent soixante-sept rectifié.
La parole est à Madame la rapporteure, pour soutenir l’amendement numéro quatre-vingt-dix rectifié.
Nous proposons de former les enseignants à la protection des données personnelles, pour qu’ils sensibilisent les élèves à ce sujet et puissent prendre les précautions nécessaires dans les classes.
La parole est à Madame Sarah El Haïry, pour soutenir l’amendement numéro cent quarante-quatre rectifié.
Il est identique à celui de Madame Forteza.
L’effort de pédagogie doit être poursuivi au sein de l’éducation nationale pour sensibiliser à la fois le corps enseignant et les élèves aux problématiques liées à la protection des données personnelles.
Si les données personnelles récoltées dans le cadre scolaire ne sont pas des données sensibles, cette sensibilisation nous paraît essentielle, car les élèves doivent prendre conscience de la nécessité de protéger l’ensemble de leurs données personnelles.
Il s’agit d’un investissement à très long terme.
La parole est à Monsieur Rémy Rebeyrotte, pour soutenir l’amendement numéro cent soixante-sept rectifié.
Il est défendu.
Je suis saisie de deux amendements, numéros soixante-deux et soixante-quinze, pouvant être soumis à une discussion commune.
La parole est à Monsieur Loïc Prud’homme, pour soutenir l’amendement numéro soixante-deux.
Le Gouvernement ne semble pas décidé à utiliser tous les outils que lui procure la réglementation européenne, en particulier le règlement général de protection des données, qu’il s’agit pourtant ici de transposer dans le droit national.
Se profile donc un risque important d’ouverture sauvage des données, sans même que la CNIL n’ait son mot à dire.
Plusieurs angles morts perdurent, dont celui des énormes fichiers de l’Éducation nationale, qui répertorient des informations sur douze millions d’élèves, mineurs pour l’écrasante majorité d’entre eux.
Nous reprenons donc la proposition de bon sens, voire salutaire, de la Commission nationale consultative des droits de l’homme – CNCDH –, qui est une institution publique indépendante.
Elle s’appuie sur l’article trente-six du RGPD, qui autorise les États à soumettre à l’approbation de l’autorité de contrôle – la CNIL, dans le cas de la France – tout traitement de données récoltées dans le cadre d’une mission d’intérêt public.
Pour La France insoumise, ce droit est surtout un devoir.
Le précédent gouvernement a fait entrer le cheval de Troie « Microsoft » dans l’éducation nationale.
Je vous adjure de vous abstenir d’aller plus loin en ouvrant à tous les vents des informations personnelles, voire intimes, qui concernent des millions d’enfants et de familles.
La parole est à Madame Sarah El Haïry, pour soutenir l’amendement numéro soixante-quinze.
Cet amendement vise à créer une nouvelle catégorie spécifique pour les traitements de données à caractère personnel dans le domaine scolaire.
En effet, avec l’utilisation croissante des outils numériques dans un cadre éducatif, les données doivent être protégées.
Or, nous nous interrogeons sur l’utilisation et le traitement des données collectées par les services souvent gratuits proposés par certaines entreprises.
Le règlement prévoit un régime protecteur encadrant le consentement des mineurs de moins de seize ans – quinze ans pour la France.
Dès lors, il n’est pas normal que les données à caractère personnel dans le domaine scolaire, portant précisément sur des mineurs, ne bénéficient pas elles aussi d’un régime spécifique et protecteur.
Quel est l’avis de la commission ? Nous avons tous exprimé nos inquiétudes à cet égard.
Madame la ministre a indiqué la direction prise par les travaux du Gouvernement.
Je propose de nous en tenir aux amendements qui ont été adoptés, dans l’attente de la co-construction, avec le Gouvernement, d’un dispositif qui sera présenté en nouvelle lecture.
Avis défavorable aux deux amendements.
Quel est l’avis du Gouvernement ? Avis défavorable, pour les raisons exposées précédemment.
La parole est à Madame Sarah El Haïry.
Pour éviter le rejet de cet amendement, et en cohérence avec les positions de mon collègue, Monsieur Latombe, qui en est l’auteur, je le retire.
Je suis saisie de quatre amendements, numéros quatre-vingt-six, quatre-vingt-onze, quatre-vingt-douze et cent quatre-vingt-quatre, pouvant être soumis à une discussion commune.
La parole est à Monsieur Erwan Balanant, pour soutenir l’amendement numéro quatre-vingt-six.
Cet amendement vise à intégrer la définition du consentement donnée par la CNIL et le groupe de travail de l’article vingt-neuf sur la protection des données – Gvingt-neuf.
Il vise à définir les qualités essentielles que doit revêtir le consentement au traitement des données personnelles : la loyauté, le caractère volontaire, libre, spécifique et informé.
Le consentement doit être délivré de manière libre et spécifique, comme le réaffirme la CNIL dans l’article six de la norme simplifiée NS-quarante-huit.
Cet amendement vise également à renforcer l’information donnée aux consommateurs, en reprenant cette norme simplifiée.
Pour cela, l’accent doit notamment être mis sur l’utilisation que le site internet fera des données personnelles, plus particulièrement lorsque le site a pour ambition de vendre les données récoltées.
Il s’agit de mettre en place une information claire, compréhensible et visible pour l’utilisateur, grâce à laquelle il aura connaissance de la finalité du traitement.
Par conséquent, ce message informatif devra être communiqué autrement que par des conditions générales ou un règlement.
Nous savons que le Gouvernement procédera, par ordonnance, à la mise en conformité de la législation relative à la protection des données personnelles, mais nous pensons que le consentement au traitement des données nécessite une attention particulière.
Le sujet est suffisamment important pour qu’un dispositif de protection soit introduit dans le présent projet de loi.
Les amendements numéros quatre-vingt-onze et quatre-vingt-douze peuvent faire l’objet d’une présentation groupée.
La parole est à Monsieur Bruno Bonnell, pour les soutenir.
L’auteure de ces deux amendements est Madame Brocard.
Avez-vous compté le nombre de messages non désirés, de spams, qui envahissent votre boîte de réception ? Vous ne le savez pas, mais vous avez donné votre consentement.
En effet, pour obtenir discrètement votre consentement, les opérateurs usent d’artifices toujours plus élaborés.
On vous demande de cliquer sur de gros boutons – « valider », « je m’inscris », « j’achète » –, suivis de petites lignes illisibles et alambiquées indiquant : « en m’inscrivant, j’accepte… ».
Beaucoup plus bas, sur la même page, figure une phrase encore plus illisible, qui vous propose de refuser le traitement de vos données.
Mais vous ne la voyez jamais, puisqu’elle a disparu quand vous avez cliqué sur le gros bouton.
Par cet amendement, nous proposons que l’action permettant de recueillir le consentement volontaire prévue par le RGPD n’ait aucune autre finalité.
Ce consentement ne doit pas être dilué dans d’autres considérations.
Il doit être possible de lire le formulaire jusqu’au bout avant de passer à une autre page.
Le consentement ne doit pas être extorqué par un artifice.
Au titre du RGPD, le consentement est donné par un acte positif clair.
Nous souhaitons que celui-ci ne génère aucune autre action, et qu’une case cochée puisse être décochée avant de passer à autre chose.
J’en viens à l’amendement numéro quatre-vingt-douze.
En deux mille quatre, la loi pour la confiance dans l’économie numérique donnait déjà une définition similaire : on entend par consentement « toute manifestation de volonté libre, spécifique et informée ».
Ces formulations ne sont que des bases de travail, tant pour les opérateurs que pour la CNIL.
La parole est à Madame la rapporteure, pour soutenir l’amendement numéro cent quatre-vingt-quatre de la commission et donner l’avis de la commission sur les autres amendements en discussion commune.
Cet amendement propose d’inscrire dans la loi de mille neuf cent soixante-dix-huit un renvoi à la définition du consentement figurant dans le RGPD.
Le consentement est la préoccupation de tous, parce qu’il est la clé de voûte du texte.
Tant que l’ordonnance n’est pas prise, il convient, pour tous les acteurs, de se référer à la loi de mille neuf cent soixante-dix-huit.
De manière exceptionnelle, nous nous sommes donc permis, du fait que nous n’avons pas pu nous pencher sur tous les grands dispositifs du texte, d’inscrire ce renvoi en attendant l’ordonnance qui sera prise par le Gouvernement.
En conséquence, avis défavorable à tous les autres amendements en discussion commune.
Quel est l’avis du Gouvernement ? Le Gouvernement émet un avis favorable à l’amendement numéro cent quatre-vingt-quatre.
Ce consentement, au sein du règlement, est du reste une des six bases légales pour considérer qu’un traitement est licite.
Il constitue une des clés de voûte de la protection des données à caractère personnel.
La notion de consentement est également précisée à l’article sept du RGPD, qui porte sur les conditions applicables au consentement, ainsi que dans plusieurs considérants, notamment les considérants trente-deux et trente-trois.
Comme vous le savez, le droit des États membres ne peut pas se borner – je l’ai déjà souligné – à recopier les dispositions directement applicables issues des règlements de l’Union.
Toutefois, afin de répondre à une attente légitime de clarification exprimée par plusieurs d’entre vous, il est possible que la loi renvoie à la définition de l’article quatre et aux conditions de l’article sept applicables au consentement.
Je suis donc favorable à l’amendement de la rapporteure ; c’est d’ailleurs ainsi que le Gouvernement procédera dans le cadre de l’ordonnance pour rappeler des droits contenus dans le règlement.
En conséquence, j’émets un avis défavorable aux autres amendements en discussion commune.
Quelle tristesse ! La parole est à Monsieur Bruno Bonnell.
N’étant pas un expert en ordonnances, je n’irai pas sur ce terrain.
L’objectif de ces amendements est de bon sens.
Il conviendra donc de trouver et d’inscrire dans la loi des systèmes de vérification technologiques permettant d’informer la personne.
Les abus sont nombreux en la matière : il ne faudrait pas qu’on nous reproche plus tard de nous être contentés d’une directive technique sans être entrés dans la technologie elle-même.
Mes chers collègues, avant de voter, demandez-vous si nous protégeons efficacement des concitoyens qui ne sont pas nécessairement informés en les renvoyant à une loi qui est très éloignée de leur quotidien.
La parole est à Madame la rapporteure.
La CNIL apportera des précisions sur l’application technique de la définition du consentement via des codes de bonne pratique, des référentiels et des outils de droit souple.
En revanche, du fait que la technologie évolue rapidement, la loi doit rester technologiquement neutre, ce qui permet de donner plus de flexibilité aux acteurs et à l’autorité de régulation.
Plusieurs orateurs sont inscrits sur l’article quatorze A.
La parole est à Monsieur Rémy Rebeyrotte.
Je tiens à remercier le Gouvernement de ce que cette question ait été l’occasion d’un véritable débat de fond, mené, lors des auditions, entre l’ensemble des acteurs et la commission, en vue de fixer l’âge du consentement en France.
Ce n’est pas un argument.
En effet, douze ans est l’âge minimum d’accès.
Quant à se rapprocher trop près de dix-huit ans, aux yeux des opérateurs, cela nous faisait entrer dans une autre logique.
L’âge de quinze ans s’est également imposé parce que c’est celui de l’entrée au lycée.
C’est un âge de maturité, qui permet le libre consentement, étant entendu que les mineurs qui n’ont pas quinze ans seront obligés d’obtenir le consentement de leurs parents pour accéder aux réseaux.
Telle est la proposition sur laquelle nous avons travaillé et qui sera soumise à votre vote.
(Applaudissements sur quelques bancs du groupe REM.) La parole est à Monsieur Jean Terlier.
Il s’agit donc d’apprécier l’âge à partir duquel un mineur est suffisamment mature pour décider sans ses parents.
Ce seuil n’a donc pas été arrêté par hasard.
La position de la commission est donc parfaitement cohérente.
La parole est à Monsieur Arnaud Viala.
Il aurait été dommageable que l’âge légal du consentement des mineurs ne figure pas explicitement dans ce texte.
Au-delà des arguments qui ont été développés par les deux précédents orateurs et auxquels je souscris, il convient de se fier également au principe de réalité.
Les jeunes, dans un pays comme le nôtre, sont surexposés très tôt au numérique.
Je parle en tant que parent d’adolescents et de préadolescents qui donnent du fil à retordre lorsqu’il s’agit de réguler leur accès au numérique.
Différer trop longtemps leur responsabilisation devant les informations qu’ils mettent en ligne serait une erreur, voire une mesure contre-productive.
De plus, l’âge de quinze ans est celui d’autres consentements légaux et il correspond aussi à l’entrée au lycée.
Cette position médiane étant logique, nous la soutiendrons via un amendement déposé par notre groupe.
La parole est à Monsieur Raphaël Schellenberger.
Nous devons nous montrer cohérents et prendre en compte la situation de la jeunesse dans la société d’aujourd’hui.
La réalité, qu’il nous est impossible de combattre, est que beaucoup de jeunes de quinze ans maîtrisent mieux les outils informatiques que leurs parents.
Nous devrons, en revanche, nous donner les moyens d’une vraie politique éducative et de sensibilisation des jeunes aux risques qu’ils encourent à livrer leurs données personnelles à des opérateurs publics ou privés.
Si tous les jeunes de quinze ans n’entrent pas au lycée, la sortie du collège permet de franchir un cap symbolique, qui se traduit par une rupture éducative et l’acquisition progressive de responsabilités sociales et sociétales.
C’est un âge cohérent et responsable.
Je suis saisie d’un amendement, numéro trente-cinq, de suppression de l’article quatorze A.
La parole est à Madame Emmanuelle Ménard, pour le soutenir.
L’article quatorze A doit être supprimé car il me semble dangereux pour nos enfants.
J’ignore si tous les députés présents dans cet hémicycle ont des enfants adolescents.
Il se trouve que j’en ai à la maison : ils sont complètement inconscients des risques liés à la transmission de toutes leurs données personnelles via internet.
(Exclamations sur les bancs du groupe FI.) L’Europe, qui joue les gros bras face aux géants des big data, nous demande aujourd’hui de permettre aux adolescents français de livrer leurs informations personnelles sans en avertir leurs parents, ce qui me semble dommageable.
Ne nous voilons pas la face.
Nous devons rester extrêmement vigilants face à ce danger.
Un certain nombre d’adolescents de quinze ans ou plus sont peut-être conscients des risques, mais à mon avis, la majorité d’entre eux ne le sont pas.
Quel est l’avis de la commission ? Un consensus a déjà émergé en commission pour fixer à quinze ans l’âge de cette fameuse majorité numérique – c’est encore le cas ce soir en séance publique.
Je me bornerai donc à exprimer mon soutien aux arguments précédemment exposés par mes collègues et à donner un avis défavorable à cet amendement.
Quel est l’avis du Gouvernement ? Madame Ménard, je ne reprendrai pas ici, devant vous, l’échange que nous avons déjà eu en commission.
J’avais expliqué pourquoi le Gouvernement n’avait pas souhaité utiliser la marge de manœuvre : en réalité, dans le cadre des négociations européennes, nous avions défendu le seuil de seize ans.
Je ne répéterai pas ma démonstration, si ce n’est pour redire devant vous que nous souhaitons tous défendre non seulement l’intérêt de l’enfant, mais aussi, peut-être, la responsabilisation des parents et le dialogue au sein des familles.
J’avais également dit en commission que je me remettais à la sagesse des parlementaires pour dialoguer sur ce sujet et trouver la solution qui leur semblerait la meilleure.
Je crois qu’un accord a été trouvé autour d’une proposition à quinze ans.
Par conséquent, fidèle à ma position, je m’en tiens à la disposition adoptée en commission et je ne peux que donner un avis défavorable à cet amendement de suppression.
La parole est à Monsieur Rémy Rebeyrotte.
Madame Ménard, je tiens à vous préciser que les GAFA, qui ont aussi été auditionnés, ne proposaient pas de fixer l’âge de la majorité numérique à quinze ans.
En outre, nous souhaitons renforcer véritablement l’information et la formation des mineurs ; dans ce cadre, la CNIL, l’éducation nationale, bien sûr, mais aussi les opérateurs eux-mêmes joueront un rôle important, sur lequel nous reviendrons dans quelques instants.
Encore fallait-il fixer une règle pour que chacun connaisse les limites et l’âge à partir duquel nous pourrons nous en remettre à la maturité des adolescents.
Nous avons donc fixé cet âge à quinze ans.
La parole est à Madame Danièle Obono, pour soutenir l’amendement numéro soixante-neuf.
Dans la lignée des recommandations de la Commission nationale consultative des droits de l’homme, cet amendement vise à ramener l’âge de la majorité numérique de quinze ans à treize ans.
Il part du constat, d’ailleurs étayé par de nombreuses études, que les jeunes sont actifs sur internet à partir de treize ans : le fait de fixer la majorité numérique à quinze ou seize ans ne correspond donc pas à la réalité.
Une majorité numérique fixée à treize ans, assortie d’un certain nombre de protections, se justifierait par le fait que c’est à partir de cet âge que les jeunes s’impliquent de plus en plus sur les réseaux sociaux.
Comme cela a été dit, d’autres pays ont déjà fixé la majorité numérique à treize ans en partant du même constat.
Par ailleurs, il convient de confier à la CNIL une mission d’information du public – nous en avons déjà discuté lors de l’examen d’autres amendements.
Ainsi, cet amendement pragmatique tient compte du fait que les adolescents et même les préadolescents accèdent très tôt à internet ; il tire toutes les conséquences de ce constat pour déterminer l’âge de la majorité numérique.
La parole est à Madame Christine Hennion, pour soutenir l’amendement numéro vingt et un.
J’aimerais commencer mon intervention par un petit clin d’œil.
Cela fait de nombreuses années que l’Europe se préoccupe de l’éducation de nos jeunes à internet.
Pour ma part, je préconise également de fixer la majorité numérique à treize ans.
J’ai déjà expliqué hier, lors de la présentation du projet de loi, les raisons de mon choix.
Aujourd’hui, en effet, soixante-quinze pourcent des enfants de onze à quatorze ans ont déjà accès à internet via un téléphone mobile : l’âge auquel cette question se pose correspond donc davantage à l’entrée en classe de sixième qu’à l’entrée au lycée.
À partir du moment où les enfants sont en possession de leur téléphone mobile, il est très difficile, voire quasiment impossible de contrôler les réseaux sur lesquels ils s’inscrivent.
Par conséquent, il sera quasi impossible de vérifier l’âge des enfants utilisant internet entre treize et seize ans.
Puisque j’ai étudié ce texte sous l’angle européen, j’ai essayé de comprendre comment cela se passait dans les autres pays.
Merci, madame la députée.
J’aimerais aller jusqu’au bout de mon explication, madame la présidente.
Je crois qu’il s’agit d’une question importante ! Vous vous exprimez déjà depuis deux minutes et vingt-cinq secondes.
Madame la présidente, il faudrait afficher le chronomètre sur nos écrans ! Laissez-moi terminer, s’il vous plaît, madame la présidente.
Encore une phrase, madame Hennion.
Selon les études européennes, les enfants les plus contraints par leurs parents sont les Français et les Allemands, mais ce sont aussi ceux-là qui trichent le plus.
La parole est à Monsieur Pierre Vatin, pour soutenir l’amendement numéro dix.
Ma position est très différente : pour ma part, je pense surtout aux enfants qu’il convient de protéger car ils sont plus vulnérables.
Pour eux, l’âge de dix-huit ans pourrait constituer un gage de sécurité.
Madame Obono, votre position manque d’homogénéité.
Pour le reste, je maintiens ma position : l’âge de quinze ans résulte d’un consensus qui a émergé depuis quelques semaines.
Avis défavorable.
Votre avis concerne-t-il aussi les amendements numéros vingt et un et dix, madame la rapporteure ? Oui, madame la présidente : la commission est défavorable aux trois amendements.
Quel est l’avis du Gouvernement ? Même position.
La parole est à Madame Christine Hennion.
Je veux répondre à l’argument tenant à la protection des jeunes.
La parole est à Monsieur Arnaud Viala.
Je souhaite réagir aux derniers propos de Madame Hennion.
Certes, j’ai rappelé le principe de réalité et j’ai invité nos collègues à tenir compte du fait que les jeunes sont de plus en plus amenés à utiliser les nouvelles technologies – davantage que nous – à des âges très précoces.
En revanche, je ne souscris pas à l’idée de fixer l’âge de la majorité numérique à quinze ans par renoncement à notre capacité de réguler.
Ça, c’est vrai ! Madame Hennion, il faut tout de même que le législateur veille à ce que des organismes informent les jeunes afin que ces derniers soient suffisamment aguerris pour savoir ce qu’ils font précisément sur internet.
Nous ne devons pas non plus oublier, dans les discussions que nous avons dans cet hémicycle, qu’il faut aussi sensibiliser les familles au fait qu’elles ne doivent pas baisser les bras.
Méfions-nous des arguments que nous avançons ! La parole est à Monsieur Éric Bothorel.
Je souhaite revenir sur les arguments que Madame Hennion n’a pas eu le temps de développer tout à l’heure.
J’ai failli déposer un amendement visant à ramener l’âge de la majorité numérique à quatorze ans, six mois, deux jours et trois heures.
(Sourires.) Je ne dis pas qu’il ne s’agit pas d’un vrai sujet – je me rallierai probablement à la position autour de quinze ans –, mais ce sont des débats dont nous avons l’habitude quand il s’agit de fixer un âge.
La question est de savoir comment nous pouvons nous assurer qu’un utilisateur qui déclare avoir onze ans a bien onze ans et que celui qui déclare avoir seize ans a bien seize ans.
Nous aurons probablement un travail à effectuer sur ce sujet ; j’aimerais donc avoir le feedback de Madame Forteza et peut-être de Madame la garde des sceaux.
Le feedback ? En français, s’il vous plaît ! La parole est à Madame Danièle Obono.
J’aimerais éclairer Madame la rapporteure, qui nous a fait part de son incompréhension face à notre position.
Vous devriez relire attentivement notre amendement, car nous proposons justement la mise en place de protections spécifiques pour les jeunes.
Dans notre amendement, il est très clair que nous demandons aux responsables du traitement des données, de manière très explicite – c’est peut-être la seule fois dans ce texte –, d’obtenir le consentement conscient, clair et explicite des internautes pour l’utilisation de leurs données.
Nous partons de la réalité telle que nous l’observons.
Dans un cadre déterminé par la CNIL, dont les moyens seraient renforcés, l’accès aux réseaux sociaux s’inscrirait dans un processus éducatif, pédagogique ; il favoriserait également l’autonomie des adolescents et préadolescents et leur donnerait les moyens de s’émanciper en utilisant internet.
C’est donc la réalité sur laquelle nous nous fondons pour donner les moyens à tous et à toutes d’être libres et protégés sur internet.
Mes chers collègues, je vous rappelle que nous devrons lever la séance à minuit.
Je vous invite donc à limiter vos prises de parole à un orateur par groupe.
La parole est à Monsieur Philippe Gosselin.
Rassurez-vous, madame la présidente : la question que nous abordons est sans doute l’un des points du débat qui focalisera le plus l’attention.
Le reste du texte, comme ce qui précédait, est certes important, mais ce sujet est particulièrement sensible, comme nous l’avons vu en commission.
Instaurer un seuil est, nécessairement, toujours un peu arbitraire.
Pourquoi, en effet, le fixer à quinze ans plutôt qu’à quatorze ou à dix-huit ? Choisir l’âge de dix-huit ans serait facile, car c’est celui de la majorité.
À seize ans, on dispose, comme cela a été dit, de capacités contractuelles et bancaires.
À treize, d’autres éléments entrent en ligne de compte.
Il me semble toutefois que nous sommes parvenus, avec un seuil fixé à quinze ans, à un point d’équilibre, même si ce n’est pas tout à fait parfait.
Cet âge renvoie en effet aussi à la « majorité sexuelle » – terme qui, je le sais, fait l’objet de différentes appréciations.
La question fait aussi référence à d’autres textes que nous aurons l’occasion, madame la garde des sceaux, d’examiner d’ici à quelques semaines dans le cadre d’autres débats.
Nous anticipons donc sur certains de ces débats et sur les âges qui pourraient être fixés alors.
Au-delà de l’âge que nous fixerons ce soir, ce qui importe est que le débat reste ouvert et, en quelque sorte, que l’alerte soit donnée quant aux besoins des utilisateurs en termes de protection et d’éducation.
La CNIL a certes, et nous en convenons tous, un rôle important à jouer en la matière, mais cette mission d’éducation et d’intérêt général et collectif dépasse largement ses compétences et ses pouvoirs.
Ce sont l’éducation nationale, les parents et les familles – en un mot : la société – qui doivent éduquer aux bonheurs – bien sûr – du numérique, mais aussi à ses risques.
Là encore, les réseaux, le numérique et toute l’économie digitale sont à la fois la pire et la meilleure des choses : à nous de les apprivoiser dans le meilleur des mondes possibles.
La parole est à Monsieur Rémy Rebeyrotte.
Comme Monsieur Gosselin, je considère que la CNIL aura un rôle particulier à jouer.
Nous avons du reste renforcé l’article premier pour bien insister sur l’importance du travail à accomplir à destination des mineurs.
Nous souhaitons également que, pour ce qui est du consentement commun du jeune et des parents, on explicite vraiment les choses, ce qui n’est pas toujours le cas aujourd’hui pour l’ensemble des opérateurs.
Je suis saisie d’un amendement numéro cent trois qui fait l’objet d’un sous-amendement numéro cent quatre-vingt-deux.
La parole est à Madame Paula Forteza, rapporteure, pour soutenir l’amendement.
Il s’agit d’un amendement de clarification rédactionnelle, tendant à bien établir un double consentement des parents et des enfants avant l’âge de quinze ans, dans un souci de co-apprentissage des usages numériques et de responsabilisation croissante des mineurs.
La parole est à Monsieur Erwan Balanant, pour soutenir le sous-amendement numéro cent quatre-vingt-deux.
Ce sous-amendement tend à apporter une clarification à la clarification en substituant aux mots : « titulaire » les mots : « ou les titulaires ».
Je rappelle en effet qu’un enfant peut avoir un papa et une maman, deux mamans ou deux papas.
Ou quatre ! Quel est l’avis de la commission sur le sous-amendement ? Cette précision est bienvenue.
Avis favorable.
Quel est l’avis du Gouvernement sur le sous-amendement et sur l’amendement ? Favorable.
Juridiquement, ça ne tient pas la route ! En effet ! La parole est à Madame Paula Forteza, rapporteure, pour soutenir l’amendement numéro douze.
Il est rédactionnel.
La parole est à Madame Marietta Karamanli, pour soutenir l’amendement numéro dix-neuf, portant article additionnel après l’article quatorze A.
Sur cet amendement, je suis saisie par le groupe Nouvelle Gauche d’une demande de scrutin public.
Le scrutin est annoncé dans l’enceinte de l’Assemblée nationale.
L’amendement concerne l’utilisation des algorithmes.
C’est un point sur lequel je tiens à insister car, si un peu plus de quatre-vingts pourcent des Français ont déjà entendu ce terme, à peine un peu plus de la moitié d’entre eux savent ce dont il s’agit.
Selon un scientifique interrogé récemment dans la presse dans une perspective de vulgarisation, un algorithme est une séquence d’instructions utilisée pour résoudre un problème.
Ce phénomène suscite des inquiétudes légitimes, car l’utilisation et la manipulation des algorithmes peuvent également avoir des répercussions sur la liberté de choix, voire sur l’égalité des personnes.
Cet amendement vise donc à faire connaître systématiquement cette utilisation dans le cadre d’une administration que nous voulons plus transparente et d’orientations que nous voulons plus équilibrées.
Nous serions donc ravis de pouvoir compter sur la mobilisation de tous autour de ce simple amendement qui exprime un principe fondamental qui doit figurer dans la loi.
Quel est l’avis de la commission ? Je m’attarderai un peu sur ce sujet, qui m’intéresse tout particulièrement, pour rappeler le droit en vigueur dans ce domaine, instauré par la loi Lemaire.
Les administrations sont tout d’abord soumises à une obligation générale de publier en ligne des règles définissant les principaux traitements algorithmiques utilisés dans l’accomplissement de leurs missions lorsqu’ils fondent des décisions individuelles : c’est donc un premier niveau d’information a priori.
De nombreuses informations sont donc déjà mises à disposition des usagers.
Par ailleurs, la loi Lemaire avait également fait du code source un document administratif, ce qui permet de l’inscrire dans la logique du droit relevant de la Commission d’accès aux documents administratifs – CADA.
L’accès au code source de ces algorithmes permet de les rejouer et de les tester à nouveau dans un cas particulier afin de disposer d’une sorte d’audit réalisé par une personne neutre.
Le droit existant me semble donc assez complet en la matière.
Je voudrais cependant demander au Gouvernement quelques précisions.
En effet, si les informations fournies à la personne qui formule une demande pour son cas particulier font l’objet de détails très précis, nous ne savons pas encore sous quelle forme s’exprimera cette obligation générale de communication.
Je souhaiterais donc savoir si le Gouvernement peut nous communiquer des détails en la matière, à propos par exemple des décrets d’application de la loi Lemaire ou des éléments relevant du niveau réglementaire, ce qui pourrait peut-être répondre aux préoccupations de Madame Karamanli.
Nous proposerons en outre d’autres amendements en ce sens, qui seront discutés par ailleurs.
Avis défavorable, donc, mais j’attends une réponse de Monsieur le secrétaire d’État.
Je passe la patate chaude ! La parole est à Monsieur le secrétaire d’État chargé du numérique, pour donner l’avis du Gouvernement.
Il me semble donc important de rappeler quelques engagements du Gouvernement.
Pour ce qui est d’abord de la maîtrise et de la transparence, que vous avez évoquées, nous partageons les mêmes objectifs.
Le droit existant y répond du reste en partie, et cet article permettra d’aller encore plus loin.
Soyons précis.
Madame la rapporteure, votre analyse a été très complète : vous avez rappelé les éléments existants, soulignant que le droit actuel satisfaisait déjà largement les demandes formulées.
Je rappellerai néanmoins dans le détail, sur le plan opérationnel, comment les choses se passeront et comment elles se passent aujourd’hui, afin d’apporter à vos questions, sinon toutes les réponses, au moins quelques-unes.
Les services de la direction interministérielle du numérique et du système d’information et de communication de l’État – DINSIC – sont mobilisés à cette fin.
Cela ne concernera cependant que des utilisateurs très avertis – dont vous faites et dont j’ai fait partie –, qui sont aussi ceux qui permettent d’éclairer le monde en disant qu’ils ont pu tester et pousser jusqu’au bout l’analyse de cette transparence.
Vous avez enfin rappelé quelles seront les informations qui seront systématiquement données au public.
Une information systématiquement fournie avec le document signalant un traitement par algorithme vous indiquera à chaque fois, sous la forme d’une mention bien visible dans la décision, les droits de communication dont vous disposez.
Vous avez rappelé, ensuite, quelles informations l’usager a le droit d’obtenir sur demande : il s’agit d’informations personnelles, délivrées sur demande, individualisées et détaillées.
Elles doivent comprendre l’intégralité des données ayant servi à faire fonctionner l’algorithme.
Toutes ces caractéristiques font l’intérêt du dispositif, mais en font aussi la limite : aujourd’hui, la seule façon de répondre à ces demandes individuelles, c’est de recourir à un traitement humain.
C’est pour cette raison d’organisation que l’on ne peut, comme vous le proposez, généraliser la transmission des données utilisées dans ces décisions administratives.
Mais vous verrez qu’à l’usage, toutes les personnes concernées par des décisions impliquant un traitement automatique de données pourront demander ces informations – je fais tout à fait confiance à la société civile, aux utilisateurs avancés, à cet égard.
Pour toutes ces raisons, il ne nous paraît pas nécessaire d’intervenir par décret : l’article de loi apportera lui-même les informations suffisantes.
Vous avez enfin demandé, de façon plus opérationnelle, quel serait le contenu de ces informations.
Avant de vous répondre, je tiens à vous dire que nous travaillons sur ce décret, sur ces questions.
Pour déterminer les informations qui seront transmises, il faut se demander lesquelles seront compréhensibles et utilisables par les usagers.
Nous travaillons actuellement à tirer toutes les conséquences de ces principes.
Nous pourrons, lors de l’examen de ce texte en deuxième lecture, apporter plus de précisions, mais je rappelle encore une fois les deux enjeux : la transparence et la maîtrise.
Les algorithmes ne font pas ce qu’ils veulent, mais ce qu’on leur dit de faire.
L’État et le Gouvernement prennent leurs responsabilités sur ce sujet.
Nous analyserons plus en détail, à l’occasion de l’examen d’un deuxième amendement, les dispositifs qui permettront de maintenir à la fois cette maîtrise et cette expertise au sujet des traitements algorithmiques.
La parole est à Madame Marietta Karamanli.
Je vous remercie, madame la rapporteure, pour votre volonté de compléter le dispositif.
Je vous remercie aussi, monsieur le secrétaire d’État, pour les éléments que vous avez évoqués.
Cependant, un élément vous a manqué pour être vraiment complet : c’est que la majeure partie des personnes concernées par de telles décisions ne demandent pas ces informations, parce qu’elles ne connaissent pas ou comprennent mal les algorithmes.
Vous avez dit, monsieur le secrétaire d’État, que nous reviendrions sur cette question en deuxième lecture.
Mais rien ne nous empêche d’adopter cet amendement dès aujourd’hui ! Je m’adresse à tous les députés : les amendements que mes collègues du groupe Nouvelle Gauche et moi-même avons défendus sont plutôt raisonnables et réfléchis.
Faisons un geste, adoptons cet amendement ; nous y reviendrons plus tard, au besoin, au cours des discussions dans notre assemblée.
La parole est à Monsieur François Ruffin.
Je ne sais pas si c’est un service que je rends à Madame Karamanli, mais je tiens à lui apporter tout mon soutien.
Nous avons nous aussi déposé des amendements allant dans ce sens, afin d’être plus attentifs à ce qui se passe au niveau des algorithmes, en rendant publiques au maximum les informations qui fondent la décision.
Nous appuyons donc cet amendement de Madame Karamanli.
Je mets aux voix l’amendement numéro dix-neuf.
La parole est à Madame Emmanuelle Ménard.
L’intelligence artificielle s’invite depuis quelques mois dans les débats, et pour cause : elle est révolutionnaire, car elle est aujourd’hui capable de simuler des décisions de justice.
C’est ce qui s’appelle la justice prédictive.
Pour y parvenir, des algorithmes permettent d’analyser une très importante quantité de données, qui sont croisées pour apporter des réponses juridiques.
L’objectif affiché est simple : désengorger les tribunaux et soulager les magistrats débordés par un nombre d’affaires en constante augmentation, alors que le nombre de juges est insuffisant.
D’autres vont même jusqu’à dire que la justice artificielle permet de répondre aux inégalités liées à la nature humaine.
Bref, la justice artificielle séduit, et il est vrai que par certains aspects on pourrait la considérer comme une avancée.
Mais attention : aucune décision de justice impliquant une appréciation sur le comportement ou la personnalité ne peut avoir pour seul fondement un traitement automatisé des données à caractère personnel destiné à évaluer certains aspects de la personnalité d’un individu.
Les risques liés à l’intelligence artificielle sont réels.
Je suis saisie de deux amendements identiques, numéros cinquante-trois et cent dix-neuf.
La parole est à Monsieur Ugo Bernalicis, pour soutenir l’amendement numéro cinquante-trois.
Par cet article, le Gouvernement souhaite autoriser la définition du profil d’une personne comme aide à la prise de décision administrative.
Rappelons qu’auparavant, définir un profil était interdit.
Aux termes de ce projet de loi, c’est seulement « prévoir » un profil qui sera interdit.
Mais vous conviendrez que la frontière juridique entre « définir » et « prévoir » est assez mince ! Il faut se méfier de cette possibilité, dont les conséquences sur notre société risquent d’être sans précédent.
Souhaitez-vous réellement instaurer, par exemple, le recours à la justice prédictive, méthode très décriée – j’en veux pour preuve le logiciel américain Compas, logiciel commercial largement utilisé pour prédire la récidive dans certains États.
Or ses prédictions ne sont ni plus pertinentes ni plus justes que celles de personnes n’ayant aucune expertise judiciaire, ou très peu.
Rappelons qu’à l’heure actuelle, le défaut d’examen individuel et personnalisé est considéré par les juges comme une erreur de droit.
Le groupe La France insoumise refuse donc les conséquences directes de cet article.
Pour nous, il conduit à une quasi-automatisation, et donc à une déshumanisation, du fonctionnement de l’administration de l’État et des collectivités territoriales.
Ce n’est pas acceptable.
La parole est à Monsieur Jean-Paul Dufrègne, pour soutenir l’amendement numéro cent dix-neuf.
Nous demandons nous aussi la suppression de cet article qui ouvre plus largement la possibilité, pour l’administration, de recourir à des décisions automatisées prises sur le fondement d’un algorithme, dans le champ des décisions administratives individuelles.
Or la CNIL regrette le manque de garanties précises lors de l’utilisation de traitements algorithmiques débouchant sur l’adoption de décisions administratives et appelle à l’approfondissement de la réflexion sur ces différents points.
Nous considérons que les enjeux juridiques et éthiques fondamentaux de cette question méritent d’être analysés de façon plus approfondie avant tout élargissement du recours aux décisions administratives automatisées.
Quel est l’avis de la commission ? Je rappelle tout d’abord qu’il est interdit de fonder des décisions de justice sur l’utilisation d’un algorithme ; cela était vrai avant le RGPD, cela sera toujours vrai après.
Il me semble que la suppression complète des décisions administratives individuelles automatisées serait un peu excessive.
Nous devons aussi travailler sur la simplification et la modernisation de l’administration.
Les citoyens ont de grandes attentes en la matière, ils sont de plus en plus exigeants : ils veulent des services publics rapides et de qualité.
Ils veulent des services publics humains ! Or nous avons besoin pour cela de pouvoir utiliser des algorithmes.
Ceci dit, des garanties suffisantes sont mises en place.
Nous avons déjà parlé des garanties d’information, de transparence, de communication ; le RGPD prévoit aussi des voies de recours.
Enfin, il est prévu que les algorithmes doivent rester maîtrisables par des humains.
Ces algorithmes ne seront pas des boîtes noires : ce n’est pas de l’intelligence artificielle.
Nous saurons toujours comment fonctionnent ces algorithmes, nous pourrons toujours comprendre comment les décisions sont prises.
Je laisse Monsieur le secrétaire d’État chargé du numérique compléter ces éléments.
L’avis de la commission est défavorable.
C’est la deuxième fois que vous refilez la patate chaude au secrétaire d’État ! La parole est à Monsieur le secrétaire d’État.
Ces technologies algorithmiques sont de plus en plus utilisées dans notre monde, non seulement dans l’économie, mais aussi dans l’administration.
Une décision algorithmique peut être plus juste qu’une mauvaise décision prise au terme d’un processus mal organisé.
Il n’est pas envisageable que l’administration se prive de ces innovations.
Cependant nous rappelons toujours une exigence, qui figure dans ce texte : la maîtrise.
Aucun algorithme non explicable ne pourra être utilisé.
Vous l’avez rappelé : les algorithmes de décisions judiciaires sont interdits et continueront de l’être.
Le RGPD prend en compte ces évolutions et autorise le recours aux algorithmes pour fonder des décisions individuelles, à condition de prévoir les mesures appropriées pour la sauvegarde des droits et des libertés : c’est l’objet de l’article quatorze.
Je voudrais à présent aller dans le détail, pour vous expliquer comment ces garanties seront mises en œuvre.
La première, c’est l’information de l’usager, dont nous avons parlé tout à l’heure.
Lorsqu’une décision le concernant a été prise sur la base d’un algorithme, il peut obtenir, sur simple demande, la communication des règles qui ont défini le traitement algorithmique et ses principales caractéristiques.
Cela répond à l’objectif de transparence de l’action de l’administration, et crée un droit à l’explication pour l’usager.
La commission des lois a clarifié le texte sur ce point, et je vous en remercie.
Je ne pense pas que l’ouverture globale permette à chaque citoyen de comprendre l’algorithme.
En revanche, leur ouverture, leur demande, leur traitement par ceux qui veulent plus de transparence, permettront de diffuser cette confiance et cette maîtrise.
La deuxième garantie, c’est le droit au recours, qui implique une intervention humaine a posteriori.
Ce droit à une intervention humaine est maintenu, et il s’applique à tous.
Il s’agit du droit à un recours hiérarchique ou gracieux contre toute décision administrative individuelle – qui est de droit commun.
Ce droit historique, je le répète, est maintenu : lorsqu’une personne concernée par une décision reposant sur un traitement automatisé de données le voudra, ce traitement sera bien repris en main par un humain.
Je le rappelle encore une fois : cette possibilité sera conservée.
L’autre élément essentiel est l’exclusion des données sensibles, que le Gouvernement a souhaitée bien qu’elle ne soit pas obligatoire aux termes du RGPD.
Enfin, vous l’avez rappelé, madame la rapporteure, il y a pour ce qui est des décisions administratives une obligation de maîtrise du traitement algorithmique par le responsable du traitement.
Pour le Gouvernement, ces garanties permettent de répondre à vos inquiétudes.
Un cadre juridique trop figé risquerait de nous empêcher d’innover, ce qui est pourtant essentiel.
La CNIL, dans son dernier rapport sur l’éthique de l’intelligence artificielle et des algorithmes, nous invite à d’autres futurs.
Elle invite à s’interroger sur l’opportunité de l’intervention humaine autrement qu’à l’échelle de chaque décision individuelle.
L’avenir est là, et mes équipes comme la CNIL travaillent beaucoup sur ces sujets.
Le gouvernement précédent avait saisi l’Institut national de recherche en informatique et en automatique, l’INRIA, du sujet de la transparence des algorithmes avec TransAlgo.
J’avais moi-même travaillé sur ce sujet au sein du Conseil national du numérique.
Ces sujets continuent d’être des sujets de réflexion ; il sera très important d’être capable de les maîtriser quand ces algorithmes seront partout dans l’administration et dans la société.
Il faudra alors être capable de les analyser et d’en garantir la transparence.
C’est aussi un des enjeux du rapport que le Gouvernement a confié à Monsieur Cédric Villani.
Il abordera ce sujet dans ses conclusions et le Gouvernement aura à se prononcer sur la capacité technologique de l’État à développer des algorithmes plus justes, plus transparents, mais aussi à les contrôler pour apporter plus de valeur au citoyen.
La parole est à Monsieur Ugo Bernalicis.
Vous nous dites que la manière dont sont construits les algorithmes est publique et que la « société civile des experts » va pouvoir regarder cela de plus près, et pourquoi pas lancer l’alerte.
Ce serait merveilleux s’il existait un statut du lanceur d’alerte – je vous renvoie ici aux amendements que La France insoumise a déposés et qui ont été rejetés.
Ce n’est donc pas à l’ordre du jour.
Il faudrait aussi que les gens qui détecteraient un problème aient la capacité de se faire entendre.
Je vous renvoie ici à l’amendement relatif au compteur Linky : je ne doute pas que vous allez l’adopter, puisqu’il vise à faire la lumière sur un problème qui reste sous les radars alors qu’il concerne le grand public.
Cela me fait penser à un reportage que le Journal de France deux a consacré à la Chine, où la vidéosurveillance utilise des algorithmes de reconnaissance faciale.
C’est ça, la société que vous voulez ? Pour nous, il est hors de question de mettre le doigt dans cet engrenage ! L’être humain n’est pas réductible à un algorithme, et il doit rester au cœur de la décision.
Votre algorithme va-t-il demander des pièces complémentaires ? Va-t-il, dans le cadre de votre loi pour une société de confiance, apporter du conseil ? Non, il va décider en fonction de données, d’une manière bête et méchante.
Très bien ! La parole est à Monsieur Laurent Furst.
Ma question est simplement le fruit d’une immense interrogation.
Votre proposition semble parée de toutes les vertus de la modernité, sauf que j’ai beaucoup de mal à déterminer où commence et où finit l’application du dispositif.
Ce flou, l’absence de lisibilité quant à son champ d’application, suscitent chez moi un certain nombre d’interrogations, même si je n’ai pas de religion particulière en la matière.
On parle là de décisions individuelles qui peuvent changer la vie des gens, or on ne connaît ni l’ampleur ni la profondeur du dispositif.
Vous dites qu’il y a des voies de recours, mais jusqu’où ? Quel est le champ d’application de cette mesure ? Vous ne l’avez pas indiqué avec précision, laissant ouvertes toute une série de questions.
Nous sommes face à un texte formidablement mal écrit et mal expliqué.
Nous n’avons pas d’hostilité de principe à l’égard de ce dispositif, mais nous ne comprenons pas jusqu’où il est possible d’aller avec une telle rédaction.
J’aimerais que vous nous expliquiez précisément quelle sera l’incidence de ce dispositif sur la vie quotidienne de nos concitoyens et qui sera concerné.
Vous avez raison : c’est essentiel.
Vos explications sont insuffisantes pour que nous prenions position.
Pardonnez-moi, mais nous sommes dans le flou absolu.
(Applaudissements sur quelques bancs du groupe LR et du groupe GDR.) La parole est à Monsieur Stéphane Peu.
Apparemment, nous ne rencontrons pas tout à fait les mêmes personnes, madame la rapporteure.
Ceux que je rencontre critiquent plus la numérisation de l’administration telle qu’elle a déjà commencé qu’ils n’expriment une aspiration à la voir se développer.
Tous ceux que je rencontre demandent qu’on réintroduise de l’humain dans les relations entre les administrations et les administrés ; j’entends davantage cela qu’une aspiration à l’automatisation.
Il aurait été utile de suivre la recommandation de la CNIL, qui nous appelle à pousser plus loin la réflexion sur ce sujet avant de légiférer.
Je pense à certain algorithme : j’ignore s’il s’agissait d’un algorithme boîte noire ou sous maîtrise humaine, mais ce que je sais, c’est qu’à cause de lui, des milliers de lycéens sont restés sans affectation à la rentrée universitaire.
Il s’agit de l’algorithme qui a fait APB (« Ah ! » sur les bancs du groupe FI.).
Cela mérite qu’on prenne le temps de la réflexion avant d’étendre ce type d’administration à de nombreux autres domaines.
(Applaudissements sur les bancs des groupes GDR et FI.) La parole est à Monsieur le secrétaire d’État.
Il s’agit de voir, dans chaque département, comment on peut les accompagner et les former en maintenant toujours l’accès à quelqu’un susceptible de les aider à traiter leurs problèmes administratifs.
Ce n’est pas le cas ! L’apport de la numérisation, c’est qu’elle libère du temps qui pourra être consacré par les agents à ceux qui en ont le plus besoin et au traitement des demandes les plus complexes.
C’est du pipeau, ça ! APB est un algorithme qui a été mis en place avant l’ère de la transparence.
Ce qui a été le plus demandé, c’est qu’on ouvre ce code, mais il l’a été de façon maladroite, puisqu’il n’y avait pas de règles indiquant comment cela devait être fait.
Mais les incidents auxquels il a donné lieu nous ont permis de lancer ce débat national et de nous poser la question de la nécessité de la transparence – et ce texte en est le reflet.
Il y a aujourd’hui, comme vous l’avez rappelé, un enjeu de maîtrise, d’accessibilité et d’inclusion numérique.
(Applaudissements sur les bancs du groupe REM.) La parole est à Madame la rapporteure.
Les citoyens se félicitent de la modernisation de l’administration quand ils peuvent s’acquitter de leurs impôts en un clic via leur portable ou quand ils peuvent savoir quels sont leurs droits en se rendant sur un site en ligne.
Allez donc dire ça à des personnes de quatre-vingts ans ! Par ailleurs, l’ouverture du code source du calculateur des impôts a été une expérience très positive, à laquelle la société civile a participé.
Elle a vu dans le détail comment les impôts dus par chaque citoyen étaient calculés.
Il est donc possible d’auditer ces algorithmes.
Il y a une grande naïveté sur ces choses ! La parole est à Monsieur Philippe Gosselin.
Je n’ai pas de problème avec la « démat » : il est évident qu’on doit vivre avec son époque, mais je ne peux pas vous laisser dire, madame la rapporteure, que les gens sont contents de payer avec leur smartphone.
Ils sont donc sanctionnés parce qu’ils sont démunis de moyens numériques de paiement.
Voilà pourquoi je ne peux pas laisser dire que tout le monde est content : ce n’est pas vrai.
Très bien ! Il y a des gens qui restent sur le bord de la route et ceux-là, il faut les accompagner.
La parole est à Madame Marietta Karamanli.
Ce débat montre bien à la fois l’inquiétude de certaines populations de nos territoires et la volonté d’aller plus loin de ceux qui se sentent à l’aise avec tout cela.
Il faut arriver à concilier ces divers besoins.
L’exemple de l’algorithme qui a été utilisé pour l’orientation des étudiants illustre le besoin de transparence, et celle-ci devrait être systématique, avant même qu’on demande quelque explication que ce soit.
C’est ainsi qu’on accompagnera et qu’on éduquera la population.
La parole est à Madame la rapporteure.
Je rejoins vos préoccupations, monsieur Gosselin : il ne faut pas qu’il y ait de dématérialisation sans médiation numérique, et c’est tout le travail que le Gouvernement est en train d’entreprendre.
Tout un réseau d’associations y travaille également au niveau local et nous devons les accompagner en tant que législateurs – et chaque député dans sa circonscription.
Ah ! si nous avions encore la réserve parlementaire ! Les associations n’ont pas les moyens de faire ce travail ! La parole est à Monsieur Loïc Prud’homme.
Cela nous permettra de gagner du temps dans les débats et cela vous permettra de consacrer du temps à faire de la pédagogie auprès des personnes qui seraient tellement heureuses de pouvoir payer leurs impôts sur smartphone.
Très bien ! La parole est à Monsieur Éric Bothorel.
Si certains amendements ont été rejetés en commission, ce n’est pas la faute d’un algorithme, mais c’est parce que ceux qui devaient les défendre étaient absents.
(Applaudissements sur les bancs du groupe REM.) C’est scandaleux ! Je vais prendre note de toutes vos absences ! La parole est à Madame la rapporteure, pour soutenir l’amendement numéro cent vingt-sept.
L’amendement tend à élargir au secteur privé les garanties d’information et de transparence que la loi Lemaire pour une République numérique a établies pour le secteur public.
Reste à savoir comment monter ce dispositif.
Dans les deux premiers cas, je souhaite ouvrir la possibilité d’appliquer les règles de transparence qui définissent le traitement automatisé, ainsi que les principales caractéristiques de sa mise en œuvre.
Dans ce cas, les personnes pourraient demander aux plates-formes comment et selon quels critères les décisions ont été prises.
Ce serait un premier pas vers une transparence des algorithmes dans le secteur privé.
Quel est l’avis du Gouvernement ? J’émets un avis favorable.
L’amendement s’inscrit en effet dans la logique que nous avons adoptée, puisqu’il vise non à contester l’arrivée des algorithmes dans certaines décisions, mais l’assortir de garanties supplémentaires.
Les dispositions proposées renforceront le texte initial en apportant une meilleure information à l’utilisateur, y compris dans le champ privé, ce que la loi Lemaire n’avait pas prévu initialement.
Pour ce faire, il faut décliner la notion d’information permettant de connaître et de contester la logique qui sous-tend le traitement automatisé prévu par l’article quinze du règlement, à travers une obligation dont l’amendement définit le contenu de manière plus concrète.
Je suis saisie de deux amendements tendant à introduire un article additionnel après l’article quatorze.
La parole est à Monsieur François Ruffin, pour soutenir l’amendement numéro soixante et un.
Je me suis fait expliquer les enjeux de ces algorithmes, dont je ne suis pas spécialiste, et qui ne visent au fond qu’à renforcer des discriminations qui existent déjà.
En effet, si l’on constate plus de fraudes auprès de la caisse d’allocations familiales parmi les gens qui habitent en banlieue, on peut craindre qu’un algorithme ne systématise les contrôles dans cette population.
De même, si l’on observe plus de retards parmi les personnes qui habitent loin de leur lieu de travail, un algorithme pourra sélectionner les candidats à un poste en fonction de leur adresse.
C’est pourquoi nous soutenons toute mesure qui irait dans le sens d’une plus grande transparence de l’utilisation des algorithmes.
Nous souhaitons donc que la CNIL puisse enquêter sur ceux-ci comme sur le reste, ce qui pourrait être fait avec la participation des citoyens et à titre expérimental.
Notre demande s’inspire des conclusions du rapport intitulé Modalité de régulation des algorithmes de traitement des contenus, remis à la secrétaire d’État chargée du numérique en mai deux mille seize – ce qui prouve son sérieux.
Très bien ! Quel est l’avis de la commission ? Avis défavorable.
Je suis d’accord avec l’esprit dans lequel a été rédigé l’amendement, mais le contrôle des algorithmes ne me semble pas devoir être confié à une entité particulière.
Toutes les associations, tous les citoyens, toute la société civile doivent pouvoir y contribuer.
C’est ce à quoi tendait l’amendement précédent, qui visait à accroître la transparence et l’accès aux ressources, et à permettre à la société civile de travailler sur ce contrôle.
Quel est l’avis du Gouvernement ? La mesure ne nous paraît pas nécessaire.
La CNIL exerce déjà ce type de mission, puisque, dans le cadre de ses prérogatives de droit commun, elle peut contrôler le respect de l’article dix de la loi qui l’a créée, lequel prohibe les décisions automatisées.
La mesure que vous demandez étant satisfaite, j’émets un avis défavorable.
La parole est à Monsieur François Ruffin.
Les deux réponses – celle de la rapporteure et de la ministre – ne coïncident pas.
Rien n’oblige à ce qu’elles coïncident.
En effet, mais j’ai le droit de le mentionner et d’en faire l’analyse.
Madame Forteza nous assure que la société civile exercera un contrôle.
Cela m’inquiète beaucoup, car je souhaite qu’il y ait un véritable gendarme, qui ne se réduise pas à quelques vagues associations et à la société civile.
Selon Madame Belloubet, ce contrôle figure potentiellement dans les missions de la CNIL, pourvu que celle-ci en fasse la demande.
Si tel est le cas, j’aimerais autant que le texte le mentionne explicitement.
Pourquoi ne pas indiquer que la CNIL doit se préoccuper de manière active de ces algorithmes, qui posent quelques problèmes ? (Applaudissements sur les bancs du groupe FI.) La parole est à Monsieur Philippe Gosselin, pour soutenir l’amendement numéro cent cinquante-quatre.
Lorsque les données sont collectées auprès de mineurs de moins de quinze ans – et non plus de seize –, il nous semble nécessaire que les responsables leur expliquent dans un langage clair et limpide les obligations qui pourraient peser sur eux.
Tel est l’objet de l’amendement.
Quel est l’avis de la commission ? La précision me paraît bienvenue.
La parole est à Monsieur Laurent Furst, inscrit sur l’article quinze.
J’ai l’impression que nous passons trop rapidement sur certaines questions que posent les algorithmes.
Je l’ai dit tout à l’heure : nous ne réfléchissons pas en profondeur, nous ne savons pas jusqu’où l’on va, alors que nous ouvrons des champs de droit intéressants.
Nous venons de dire que les algorithmes rendront des décisions individuelles.
Tout acte administratif peut faire l’objet d’un recours, à travers la saisine du tribunal administratif.
Nous sommes donc dans un champ relativement clair et simple.
Cependant, lorsque la décision est dolosive et qu’elle crée un préjudice, contre qui le citoyen pourra-t-il se retourner ? Nous avons inventé la notion de mise en examen des collectivités.
Auparavant, c’était leur représentant juridique qui portait la responsabilité juridique en cas de recours.
Quand une décision provient d’un algorithme, qui en assume la responsabilité juridique ? La question se pose également dans le cas de la conduite automatisée.
Dans un flux de circulation, il existe des champs de responsabilité multiples.
Contre qui pourra-t-on se retourner ? Chaque pays va créer son droit face à cette situation.
Je ne suis pas sûr que le nôtre soit très clair sur la question ni même que nous l’ayons pleinement anticipée.
En tout cas, cela méritait d’être dit.
Et cela a été entendu.
Je suis saisie de trois amendements identiques, numéros soixante-quatorze rectifié, cent quarante-neuf rectifié et cent soixante rectifié.
La parole est à Madame Sarah El Haïry, pour soutenir l’amendement numéro soixante-quatorze rectifié.
Dans la continuité de l’intervention de Monsieur Furst, l’amendement numéro soixante-quatorze rectifié vise à anticiper certaines situations.
La médiation se déroulera suivant les dispositions de la section un du chapitre premier du titre deux de la loi numéro quatre-vingt-quinze-cent vingt-cinq du huit février mille neuf cent quatre-vingt-quinze relative à l’organisation des juridictions et à la procédure civile, pénale et administrative.
En cas d’échec de cette médiation, la personne concernée pourra toujours saisir la CNIL.
Nous insistons sur la lourdeur actuelle des démarches.
Le recours à une médiation permettra de soulager les services de la CNIL et résoudra une réelle difficulté du quotidien.
La parole est à Monsieur Philippe Gosselin, pour soutenir l’amendement numéro cent quarante-neuf rectifié.
Il arrive qu’on persévère, quand on est sûr d’avoir quelques bonnes idées.
Avec George Pau-Langevin, qui a mal tourné, puisqu’elle est devenue ministre il y a quelque temps, j’avais écrit un rapport d’information en vue d’améliorer l’accès au droit et à la justice, ce qui est une nécessité pour la République.
Ce rapport réservait une place importante à la médiation, qui permet d’accéder à certains éléments de manière plus apaisée que par des voies de recours classiques.
Dans tous les cas, les intéressés pourraient saisir la CNIL, mais il est bon d’inscrire dans le texte la possibilité d’une médiation, qui aurait vocation à s’appliquer plus largement et dans d’autres secteurs que le numérique.
Nous pourrions y revenir prochainement quand nous examinerons le projet de loi de programmation annoncé sur la justice.
La parole est à Monsieur Pierre-Henri Dumont, pour soutenir l’amendement numéro cent soixante rectifié.
Monsieur Gosselin l’a rappelé : il s’agit d’un vieux débat.
Dans un souci de fluidité, nous devons trouver la meilleure réponse à apporter à l’administré ou à l’usager.
Dans certains cas, la médiation permettra de répondre à des inquiétudes, tout en désengorgeant la CNIL, qui, demain, pourrait faire face à de très nombreuses saisines.
Quel est l’avis de la commission ? Je reconnais que la médiation peut fluidifier ce type de contentieux, mais le droit commun permet déjà d’y recourir.
La précision n’est donc pas utile.
Avis défavorable.
Quel est l’avis du Gouvernement ? J’ajoute que, pour intéressants qu’ils soient, ces processus allongeraient les délais, ce qui ne me semble pas correspondre à l’objectif poursuivi par les auteurs des amendements.
Avis défavorable.
La majorité est fracturée ! La parole est à Madame Danièle Obono, pour soutenir l’amendement numéro cinquante-cinq.
L’interdiction de la collecte de certaines données personnelles sensibles, à des fins explicites d’identification d’une personne, doit souffrir une exception, lorsque cette collecte, faite par des organes étatiques, l’est pour des motifs de sécurité intérieure.
Ces motifs sont évidemment compréhensibles et justifient une dérogation, qui doit cependant être autant encadrée que possible.
C’est le sens de cet amendement, qui vise à la limiter au strict nécessaire sans empêcher la poursuite d’opérations indispensables à la sécurité de l’ensemble des citoyens et des citoyennes.
Quel est l’avis de la commission ? Il me semble que la notion de « risque majeur » n’est pas très claire.
On ne la rencontre pas dans d’autres dispositions législatives de ce type.
Par ailleurs, l’encadrement existe, puisque le Conseil d’État fixera la liste des traitements autorisés à déroger au droit à la communication d’une violation de données en présence d’un tel risque.
Il n’est donc pas nécessaire d’instituer des garanties supplémentaires.
Avis défavorable.
La parole est à Monsieur Ugo Bernalicis, pour soutenir l’amendement numéro cinquante-six.
Le Conseil d’État fixera, en lien avec la CNIL, la liste des domaines dans lesquels on pourra se soustraire à l’obligation d’informer les intéressés en cas de violation des données personnelles.
Cela peut se justifier par des raisons importantes liées à la défense ou à la sécurité nationale, ce que nous ne contestons pas.
Néanmoins, nous ne voudrions pas que ces raisons justifient, par principe, l’absence de communication des données, quand bien même elles ne présenteraient pas de caractère sensible et déterminant.
Aussi vous proposons-nous de faire intervenir dans la procédure le juge des libertés et de la détention – JLD –, seul garant des libertés individuelles, conformément à l’article soixante-six de la Constitution, pour valider cette absence de communication.
À défaut, « la porte serait ouverte à toutes les fenêtres ».
Sur l’amendement numéro soixante et onze rectifié, portant article additionnel après l’article quinze, je suis saisie par le groupe La France insoumise d’une demande de scrutin public.
Le scrutin est annoncé dans l’enceinte de l’Assemblée nationale.
Quel est l’avis de la commission sur l’amendement numéro cinquante-six ? Il serait compliqué de faire intervenir le JLD dans un cadre administratif.
Avis défavorable.
Quel est l’avis du Gouvernement ? Avis également défavorable sur ce nouvel appel au JLD.
La parole est à Monsieur Ugo Bernalicis.
Cette loi institue une procédure administrative de visites domiciliaires, encadrée – je vous le donne en mille – par le juge des libertés et de la détention.
Ne trouvez-vous pas étrange que ce magistrat puisse intervenir dans le cadre d’une procédure administrative ? Comment est-ce possible ? Tout simplement parce que nous l’avons écrit dans la loi.
Nous avons décidé que le juge des libertés et de la détention, en tant que juge garant des libertés individuelles, conformément à l’article soixante-six de la Constitution, délivrerait une autorisation préalable à ces visites.
Je considère donc que votre argument, selon lequel le JLD n’a rien à faire dans une procédure administrative, n’est absolument pas valable : nous sommes au contraire nombreux à penser qu’il est le plus à même d’agir en la matière.
Que vous ne vouliez pas qu’un juge intervienne dans la procédure, pour la valider, au moment où les faits surviennent, cela vous regarde.
Nous estimons, pour notre part, que cela offrirait à nos concitoyens une meilleure garantie pour l’exercice de leurs libertés individuelles.
La parole est à Madame la garde des sceaux.
Je n’ai pas dit que le JLD ne devrait pas intervenir dans cette occurrence en raison de la nature administrative de la mesure.
J’ai affirmé – de manière très elliptique, j’en conviens, et c’est pourquoi je vous apporte cette précision – que faire intervenir le JLD dans ce type de dispositif serait contraire à la philosophie qui l’anime, à savoir la promotion de l’auto-responsabilisation.
Je ne vois pas ce qu’apporterait ici l’intervention d’un juge.
On peut également se demander comment il pourrait exercer son contrôle.
En effet, il ne pourrait apprécier la réalité du risque que s’il disposait d’une habilitation à connaître d’une question liée à la sécurité ou à la défense nationale.
La parole est à Monsieur Ugo Bernalicis.
Je reviens sur la loi renforçant la sécurité intérieure et la lutte contre le terrorisme.
Ce texte n’accorde pas d’habilitation au JLD pour se prononcer, et nous lui avons pourtant reconnu cette compétence.
Nous affirmons que la procédure d’autorisation par la CNIL et le Conseil d’État va se traduire par le fait que, dans un domaine donné, on ne communiquera pas les données, quelle que soit leur sensibilité et quelles que soient les circonstances.
Aussi estimons-nous qu’il serait opportun qu’une personne indépendante, garante des libertés individuelles, intervienne en la matière : le JLD nous semble tout indiqué.
La parole est à Monsieur Loïc Prud’homme, pour soutenir l’amendement numéro soixante et onze rectifié, portant article additionnel après l’article quinze.
Cet amendement a trait aux compteurs « intelligents » Gazpar et Linky, qui n’ont d’intelligent que le nom et devraient plutôt être nommés des « capteurs de données ».
Mais non ! De fait, les compteurs Gazpar et Linky collectent, quasiment en temps réel, votre consommation de gaz naturel ou d’électricité.
Les données collectées peuvent être envoyées à votre opérateur énergétique afin de constituer votre courbe de charge, c’est-à-dire la courbe de votre consommation au cours d’une journée.
Si vous acceptez cela, vos données sont enregistrées par votre opérateur énergétique.
D’ailleurs, dans le cas de Linky, ENEDIS ne cache pas que ce qui l’intéresse, ce sont les données personnelles.
Son président, Philippe Monloubou, n’a-t-il pas déclaré, en février deux mille dix-sept : « L’entreprise doit anticiper pour faire évoluer son « business model » car nous sommes désormais également un opérateur de big data. » Nous sommes là au cœur du sujet.
Par cet amendement, nous souhaitons mettre fin à une atteinte majeure aux droits et libertés fondamentales numériques – plus particulièrement, en l’occurrence, au droit au consentement.
L’objectif affirmé de l’efficacité énergétique semble louable – bien qu’illusoire, comme l’a souligné la Cour des comptes dans son rapport public annuel.
Nous estimons que la transposition du règlement RGPD doit rendre obligatoire – je dis bien obligatoire – l’obtention du consentement des personnes chez qui l’on souhaite implanter ces compteurs, qui sont, je le répète, des capteurs de données.
Quel est l’avis de la commission ? Le rapport de la Cour des comptes évoque plus le business model du déploiement de ces compteurs dans les foyers que le mode de traitement des données par les entreprises.
Je peux toutefois apporter quelques précisions à ce sujet.
Le gestionnaire du réseau de distribution ne collecte par défaut que des données de consommation globale des foyers sur une journée ; il ne s’agit donc pas, à proprement parler, de données personnelles.
La collecte des données de consommation fine, par tranche horaire ou par demi-heure, est, pour sa part, soumise à l’accord de l’usager : son consentement est donc requis.
Quant à la transmission des données de consommation détaillée à des sociétés tierces, notamment à des fins commerciales, elle ne peut intervenir qu’avec l’accord de l’abonné.
En tout état de cause, quand le RGPD entrera en application, ces sociétés devront offrir toutes les garanties nécessaires en ce qui concerne le consentement du client.
La commission émet donc un avis défavorable à l’inscription de cette précision dans la loi.
C’est la raison pour laquelle j’émets un avis défavorable sur votre amendement.
La parole est à Monsieur Gilles Lurton.
Madame la ministre, on peut soutenir, en effet, que ces compteurs ne sont pas l’objet du présent texte, mais ils n’en constituent pas moins un problème.
Dans les mois qui ont suivi l’entrée en vigueur de la loi sur la transition énergétique, les abonnés n’étaient pas en mesure de refuser l’installation d’un compteur Linky.
Ils le peuvent depuis quelque temps, mais ces dispositifs continuent à créer de nombreuses difficultés dans nos communes.
Les mouvements dits « anti-Linky » se font aujourd’hui, de mon point de vue, de plus en plus pressants.
Pourquoi ? Quand une personne s’oppose à l’installation d’un compteur Linky, ENEDIS, je l’ai dit, respecte leur volonté.
En revanche, dans une copropriété, le compteur est automatiquement installé, même si les copropriétaires ne le souhaitent pas, ce qui entraîne, à l’heure actuelle, de nombreux litiges dans les communes – dont, j’imagine, nous sommes tous, ici, saisis régulièrement.
Sur le plan scientifique, je ne suis pas capable de me prononcer sur les effets éventuels du compteur Linky.
On m’apporte une multitude de démonstrations et de renseignements, qui me donnent le sentiment que tout cela est extrêmement compliqué.
L’ANSES – Agence nationale de sécurité sanitaire de l’alimentation, de l’environnement et du travail – avait été saisie de ce dossier et avait conclu à l’absence de danger pour la santé.
Il n’est d’autre solution que de s’appuyer sur ce type d’expertises scientifiques pour se forger un jugement.
Il n’en reste pas moins qu’un véritable problème se pose dans notre pays, qui est presque de nature démocratique.
La parole est à Monsieur Loïc Prud’homme.
Monsieur Lurton, même lorsqu’on s’oppose à l’installation du compteur, il est souvent posé de force.
Plus maintenant ! Ma question porte surtout sur le traitement des données.
Madame la ministre, vous ne pouvez pas dire que ce sujet ne relève pas de ce texte : il s’agit de capteurs de données.
On en a installé à ce jour huit millions et le chiffre doit atteindre trente-cinq millions : c’est donc bien de la collecte massive de données.
Ne nous dites pas que ce n’est pas aujourd’hui qu’il faut en parler : c’est un véritable problème et votre argument reposant sur le consentement de l’intéressé ne tient pas une seconde, puisqu’il s’agit de pose forcée.
Demain, les données seront collectées foyer par foyer : si vous ne cochez pas la bonne case, elles seront transmises, et nous n’avons aucune garantie quant à l’avenir.
Il faut donc que l’on puisse refuser la pose de ces appareils.
C’est en effet un principe démocratique de base.
Monsieur Ruffin, je ne peux vous donner la parole, Monsieur Prud’homme s’étant déjà exprimé.
Je mets aux voix l’amendement numéro soixante et onze rectifié.
La parole est à Monsieur Jean Terlier, inscrit sur l’article seize A.
Le législateur français n’entendait pas alors seulement se conformer à l’obligation d’harmonisation des pratiques à l’échelle européenne, mais voulait donner aux internautes des outils puissants destinés à contrôler et à sanctionner les e-commerçants.
Le développement de la e-consommation – ou plus exactement les nouvelles modalités de consommation, de communication, d’information et de recherche – justifie que l’action collective ne soit pas circonscrite au domaine particulier du droit de la consommation.
C’est pourquoi elle figure également dans la loi du vingt-six janvier deux mille seize de modernisation de notre système de santé – et donc dans le droit de la santé.
Il n’est pas davantage surprenant qu’elle ait été définie par la suite dans un cadre juridique et procédural commun à toutes les matières du droit, sur le fondement duquel un tel recours est désormais possible.
L’action de groupe prévoit un recours en réparation d’un préjudice matériel.
Elle autorise plusieurs personnes s’estimant victime d’un même préjudice provoqué par un même professionnel à se regrouper et à agir en justice d’une seule et même voix.
En matière de traitement des données à caractère personnel, elle procède d’une finalité exceptionnellement distincte.
Elle vise ici non plus la réparation matérielle du préjudice subi, mais la seule cessation des manquements à la loi par leur auteur.
Elle perd donc sa vocation initiale, pourtant confirmée en deux mille seize par le législateur.
Tel est l’objectif visé par l’article seize A : permettre l’action en réparation matérielle, y compris en matière de données à caractère personnel, auparavant exclues du champ de l’action de groupe, et rendre à celle-ci toute son efficacité et son fondement.
La parole est à Monsieur Thibault Bazin, pour soutenir l’amendement numéro quatre-vingt-deux, tendant à supprimer l’article seize A.
Même si l’on peut en comprendre l’intérêt, le dispositif s’apparente à une surenchère législative par rapport aux normes européennes.
C’est pourquoi Jean-Louis Masson et moi-même proposons de circonscrire l’action de groupe à la seule cessation du manquement, comme le prévoit la loi Informatique et libertés, et non de l’étendre à la réparation du préjudice, comme le suggère l’étude d’impact.
Quel est l’avis de la commission ? L’article seize A, qui est issu d’un consensus, représente l’une des grandes avancées obtenues par la commission, car il permet de mettre en œuvre efficacement les dispositions du RGPD.
Pour garantir les équilibres du texte, il est indispensable de prévoir une voie de recours à travers les associations : celles-ci pourront déposer des plaintes individuelles qui, sans elles, ne verraient pas le jour, car ce sujet est complexe et technique.
La commission est donc défavorable à l’amendement.
Nous ne souhaitons pas revenir sur la position adoptée en commission.
L’avis du Gouvernement est donc défavorable.
La parole est à Monsieur Jean-François Cesarini, pour soutenir l’amendement numéro cent soixante-quatre.
Le régime général de l’action de groupe est régi par les articles soixante-six et suivants de la loi de modernisation de la justice du vingt et unieme siècle.
L’article soixante-deux en donne la définition.
Quant au régime de l’action de groupe en matière de données personnelles, il est prévu par l’article quarante-trois de la loi Informatique et libertés promulguée en mille neuf cent soixante-dix-huit.
L’article seize A du présent texte, introduit en commission, vise à rapprocher les deux régimes en ouvrant le droit à la réparation du préjudice.
L’amendement numéro cent soixante-quatre s’inscrit dans ce cadre.
Il reprend la rédaction du régime général.
Concrètement, un juge ayant à statuer sur la recevabilité d’une action de groupe est tenu d’examiner les cas individuels des personnes lésées, même si elles sont représentées par une association agréée.
Il examine donc le problème globalement, mais aussi en fonction de chaque cas individuel.
Quel est l’avis de la commission ? Il s’agit d’une harmonisation rédactionnelle tout à fait bienvenue entre le présent projet de loi et la loi de modernisation de la justice du vingt et unieme siècle à laquelle la commission est favorable.
Je suis saisie de deux amendements identiques, numéros quatre-vingt-sept et cent soixante-cinq.
La parole est à Madame la rapporteure, pour soutenir l’amendement numéro quatre-vingt-sept.
C’est un amendement de coordination.
La parole est à Monsieur Jean-François Cesarini, pour soutenir l’amendement numéro cent soixante-cinq.
Il s’agit de donner une base légale claire à la procédure suivie par le juge administratif.
La rédaction de l’article seize A retenue par la commission des lois prévoit le recours à la procédure de réparation individuelle en cas d’action de groupe visant à la réparation du préjudice.
Seule la base légale de droit privé a été insérée, privant le juge administratif de toute possibilité d’action.
L’amendement rétablit une base légale de droit public et corrige cette erreur, ce qui permettra au juge administratif d’agir.
Je suis saisie de quatre amendements identiques, numéros soixante-dix, soixante-treize, cent neuf et cent cinquante.
La parole est à Madame Danièle Obono, pour soutenir l’amendement numéro soixante-dix.
Cet amendement porte sur le recours collectif, qui nous semble particulièrement pertinent pour agir contre les acteurs d’internet dès lors que des collectes de données sont en jeu.
Un tel recours permet de mettre à jour, de façon probante, le caractère massif et la dimension systémique de la pratique ainsi dénoncée.
Il permet aux requérants d’associer leurs forces et donc de peser davantage dans la balance face aux acteurs du numérique.
Il faut ouvrir le plus possible aux citoyens la possibilité de procéder à une demande de réparation du préjudice subi.
Tel est le sens de cet amendement.
La parole est à Monsieur Erwan Balanant, pour soutenir l’amendement numéro soixante-treize.
La parole est à Monsieur Stéphane Peu, pour soutenir l’amendement numéro cent neuf.
Cet amendement, qui s’inspire d’une préconisation du Conseil national des barreaux, donne à un avocat la possibilité de se substituer à une association agréée si celle-ci n’existe pas, afin d’assurer aux justiciables la meilleure représentation possible.
La parole est à Madame Véronique Louwagie, pour soutenir l’amendement numéro cent cinquante.
Néanmoins, elle ne prévoit pas certains cas, notamment l’absence d’association agréée, son inaction ou son incapacité à agir.
Cet amendement apporte une solution à ce problème en permettant aux personnes concernées d’être représentées par un avocat dans quatre situations, notamment si les associations n’existent pas ou ne sont pas à même d’intervenir.
Quel est l’avis de la commission ? La commission a choisi de s’inscrire dans le cadre prévu par la loi de modernisation de la justice du vingt et unieme siècle.
De surcroît, l’article quatre-vingts du RGPD comporte une définition restrictive des organismes habilités à agir, s’en tenant aux associations et organisations à but non lucratif, ce qui en exclut les avocats.
L’avis de la commission est donc défavorable.
La parole est à Madame la rapporteure, pour soutenir l’amendement numéro quatre-vingt-huit.
C’est un amendement rédactionnel.
Je suis saisie de deux amendements, numéros cent dix et cent cinquante et un, pouvant être soumis à une discussion commune.
La parole est à Monsieur Stéphane Peu, pour soutenir l’amendement numéro cent dix.
Il s’agit de permettre aux associations et organismes mandatés de mener efficacement une action de groupe, dont l’avance des frais peut s’avérer dissuasive faute de mesures d’accompagnement appropriées.
Sur ce sujet, la législation québécoise fournit un excellent exemple.
Le législateur québécois a créé dès mille neuf cent soixante-dix-huit un fonds d’aide au recours collectif destiné à fournir une aide financière aux personnes désireuses d’en engager un.
Il s’agit d’une mesure de justice et d’efficacité.
La parole est à Monsieur Philippe Gosselin, pour soutenir l’amendement numéro cent cinquante et un.
Il s’agit de rendre effective l’action de groupe.
Je souscris aux arguments avancés par Stéphane Peu.
Quel est l’avis de la commission sur ces deux amendements ? Cette idée me semble intéressante et je l’ai approfondie.
J’ai alors constaté qu’un tel recours est déjà possible dans le cadre des juridictions judiciaires.
Nos échanges avec la CNIL ont montré sa réticence à progresser sur ce point, faute de compétence pour traiter ce type de contentieux.
La CNIL s’en tient donc à l’objectivation du manquement, pour laquelle elle dispose des moyens techniques adéquats, laissant au juge judiciaire les autres aspects du contentieux.
L’avis de la commission est donc défavorable.
La parole est à Madame Laurence Trastour-Isnart, pour soutenir l’amendement numéro quatre-vingt-trois.
Permettre la saisine du Conseil d’État par la CNIL crée un aléa judiciaire important qui pourrait mettre en péril certaines activités nécessitant des transferts de données hors de l’Union européenne.
Il convient donc de supprimer l’article dix-sept.
Je suis saisie de deux amendements tendant à la création d’un article additionnel après l’article dix-sept.
La parole est à Madame Émilie Cariou, pour soutenir l’amendement numéro cent soixante-neuf.
Cet amendement vise à créer un droit de communication entre la CNIL et la direction générale des finances publiques – DGFiP.
Il s’agit de conférer des pouvoirs supplémentaires à la CNIL, dont disposent déjà d’autres autorités administratives indépendantes telles que l’Autorité de la concurrence ou l’Autorité des marchés financiers.
Quel est l’avis de la commission ? Avis défavorable.
Ils peuvent recueillir, notamment sur place ou sur convocation, tout renseignement et toute justification utiles et nécessaires à l’accomplissement de leur mission ».
Cela concerne en particulier l’administration fiscale.
La parole est à Madame Émilie Cariou.
Ces dispositions permettent-elles de passer outre le secret fiscal ? Je n’en suis pas certaine.
La parole est à Madame la rapporteure.
Le secret fiscal n’est pas mentionné parmi les exceptions.
La parole est à Madame Émilie Cariou.
Je vérifierai.
Pour le moment, je retire l’amendement.
La parole est à Monsieur Éric Bothorel, pour soutenir l’amendement numéro cent soixante-treize.
Cet amendement vise à rendre nulles les clauses contraires à l’esprit du RGPD, afin que les fabricants et distributeurs offrent aux utilisateurs finaux des alternatives plus respectueuses de leur vie privée.
Quand vous allumez votre smartphone pour la première fois, vous devez saisir différents paramètres – votre fuseau horaire, par exemple.
Ensuite, vous pouvez choisir d’installer des applications.
Mais la pratique, aujourd’hui, c’est l’absence de choix : l’application qui permet de naviguer sur internet et le moteur de recherche vous sont imposés.
Ces applications natives vous sont imposées, sur votre smartphone, votre tablette, votre ordinateur, voire votre box.
Chacun pourrait ainsi faire valoir son navigateur ou son moteur de recherche.
Je ne doute d’ailleurs nullement que toutes ces applications seront conformes au RGPD, mais certains voudront peut-être offrir des services supplémentaires – par exemple, ils ne collecteront pas de données.
C’est ce libre choix que nous voulons donner aux utilisateurs.
Je fais partie d’une catégorie un peu informée ; quand je décide de ne pas dire « oui » en cliquant sur la petite flèche en bas à droite, je sais à quoi je me soustrais.
Ce n’est pas le cas de tout le monde.
Enfin, tout à l’heure, j’ai employé le mot anglais feedback, et je prie ceux qui ont réagi de m’en excuser.
Mais, puisqu’ils parlent d’« économie digitale », je leur devais bien ça ! (Sourires.) Quel est l’avis de la commission ? Avis défavorable.
Nous avions décidé de retravailler l’amendement ; il me semble que la rédaction n’est pas encore tout à fait aboutie.
Remettons l’ouvrage sur le métier.
Quel est l’avis du Gouvernement ? Avis défavorable.
Nous avons examiné votre amendement de façon approfondie, mais il nous semble que le RGPD satisfait une partie de vos demandes.
Le considérant soixante-dix-huit du règlement, ainsi que son article vingt-cinq, impose déjà aux responsables de traitement de proposer des biens ou services qui offrent par défaut ou dès leur conception le plus haut niveau de protection des données personnelles.
Seules les données nécessaires pour chaque finalité spécifique de traitement doivent être traitées.
De plus, le considérant trente-deux du RGPD donne une définition du consentement qui implique que l’utilisateur d’un smartphone ne pourra pas se voir imposer l’utilisation, par défaut, d’un navigateur donné.
Dans votre exposé des motifs, vous constatez que « la quasi-totalité des smartphones commercialisés en France […] sont équipés d’un système d’exploitation […] qui impose par défaut le même moteur de recherche à leurs utilisateurs ».
Vous estimez que « l’utilisation d’un seul service collectant des données à caractère personnel pour d’autres fins que celle de la fourniture de service en question ne permettrait pas d’obtenir un consentement libre de la personne concernée ».
Celui-ci sanctionne les abus de position dominante, mais il est beaucoup plus délicat d’imposer à titre préventif des obligations restrictives, plus difficiles à justifier.
Nous sommes évidemment sensibles à votre objectif de promotion du développement des acteurs qui offrent des services plus respectueux de la protection des données personnelles.
L’Europe a là l’opportunité de se doter d’un véritable avantage compétitif.
Mais cette réflexion me semble vraiment devoir être conduite dans un cadre européen, et une expertise approfondie des implications juridiques, économiques et industrielles de vos propositions est indispensable.
Je suis tout à fait disposée à poursuivre ces échanges constructifs, avec tous les parlementaires qui le souhaiteraient.
La parole est à Monsieur Philippe Gosselin.
Votre position, madame la garde des sceaux, est raisonnable.
Mais notre collègue Éric Bothorel soulève une question importante.
Nous ne voulons pas nous voir imposer des services « à l’insu de notre plein gré », comme on dit ! De telles dispositions pourraient redonner confiance dans la vie numérique, et faire tomber quelques fantasmes.
Nous devons absolument creuser cette question, collectivement.
La parole est à Monsieur Cédric Villani.
Loin de moi l’idée de contredire Madame la rapporteure et Madame la garde des sceaux, mais je voudrais apporter, sur le fond, de l’eau au moulin de notre collègue Éric Bothorel.
Ces problèmes sont essentiels.
Les moteurs de recherche constituent un sujet particulièrement sensible, parce qu’ils donnent accès à l’information.
Le très intelligent algorithme pagerank, qui a permis l’essor de Google, appartient à l’histoire des sciences et des technologies.
Il faut rappeler aussi que la concurrence, en ce domaine, peut être rude.
Je vais vous raconter une petite mésaventure qui m’est arrivée, comme à d’autres sans doute.
Ces pratiques sont inacceptables et constituent une véritable distorsion de concurrence.
Nous confions aux moteurs de recherche nos rêves, nos espoirs, nos peurs, nos intérêts aussi.
Ces données sont précieuses et il est important que nous nous saisissions activement de ce sujet.
(Applaudissements sur les bancs des groupes REM et LR, ainsi que sur plusieurs bancs du groupe GDR.) La parole est à Monsieur François Ruffin.
J’entends parler de libre choix, de consentement éclairé, ou à l’inverse de services imposés « à l’insu de notre plein gré ».
Vous me pardonnerez de revenir un peu en arrière, mais il y a un fossé entre la loi que nous écrivons ici et la réalité ! Quand quelqu’un vient chez vous poser un compteur Linky, il commence par dire « bonjour, c’est EDF ».
Mais ce n’est pas EDF qui pose les compteurs Linky ! Il dit ensuite que c’est obligatoire, ce qui n’est pas vrai.
Je ne fais là que vous rapporter des témoignages, qui nous assurent aussi que l’entreprise revient jusqu’à ce que la personne accepte la pose de ce compteur.
Là aussi, la question du libre choix et du consentement éclairé est posée.
La parole est à Monsieur Rémy Rebeyrotte.
Nombre d’entre nous estiment que la question posée par Éric Bothorel est importante.
Nous sommes néanmoins sensibles aux arguments du Gouvernement.
La rédaction de l’amendement n’est pas aboutie, et il faut travailler sur les éventuelles conséquences économiques et industrielles – les éventuels effets de bord – comme sur la compatibilité avec le droit européen.
Nous devons creuser cette question – je dis cela avec la volonté d’aboutir.
Je serais donc favorable à un retrait de l’amendement, et à un travail avec le Gouvernement.
Il serait dommage de passer à côté d’une question si fondamentale.
La parole est à Monsieur Éric Bothorel.
J’entends tous les arguments qui ont été avancés.
Depuis la première présentation de cet amendement en commission, les échanges ont été constants.
Je veux dire ici, de façon forte, formelle, que nous n’abandonnerons pas ce sujet.
Il ne s’agit évidemment pas de mettre la France au ban de l’Europe ; il s’agit d’entraîner l’Europe vers un modèle du numérique défendu par la France.
En matière de protection des données, nous ne perdrons rien à être parfois un peu en avance, à envoyer des signaux.
Nous serons, je le crois, suivis, et pas uniquement en Europe.
Je prends acte des propositions de Madame la garde des sceaux, et je me réjouis de voir Monsieur le secrétaire d’État chargé du numérique opiner du chef.
Je retire l’amendement, pour me mettre immédiatement au travail avec tous ceux qui l’ont cosigné, afin d’atteindre notre but dans des délais acceptables.
(Applaudissements sur plusieurs bancs du groupe REM.) La parole est à Monsieur Loïc Prud’homme, pour soutenir l’amendement numéro cinquante-sept.
À l’instar de la CNIL, nous souhaitons promouvoir le renforcement du droit commun plutôt que son démantèlement ou la facilitation des fichiers.
Nous ne faisons ici qu’utiliser les marges de manœuvre prévues par le droit européen, au travers de la notion de mission d’intérêt public.
La parole est à Madame la rapporteure, pour soutenir l’amendement numéro treize.
Amendement rédactionnel.
La parole est à Madame la rapporteure, pour soutenir l’amendement numéro quatorze.
Amendement rédactionnel.
La parole est à Madame la rapporteure, pour soutenir l’amendement numéro quinze.
Amendement rédactionnel.
La parole est à Madame la rapporteure, pour soutenir l’amendement numéro seize.
Amendement de précision.
La parole est à Madame la rapporteure, pour soutenir l’amendement numéro dix-sept.
Amendement de précision.
La parole est à Madame la rapporteure, pour soutenir l’amendement numéro dix-huit.
Amendement de clarification.
Je suis saisie de quatre amendements identiques, numéros trente et un, cinquante-huit, cent vingt et cent vingt-neuf.
La parole est à Madame Emmanuelle Ménard, pour soutenir l’amendement numéro trente et un.
Je ne comprends pourquoi il faut ici recourir aux ordonnances.
Vous faites valoir que celles-ci serviront uniquement à apporter les corrections formelles et les adaptations nécessaires à la simplification et à la cohérence du droit national par rapport au droit européen.
Le travail parlementaire, qui est l’un des éléments essentiels de notre démocratie, ne peut être ainsi balayé d’un revers de main.
Je ne répéterai jamais assez à quel point le recours aux ordonnances entretient la défiance de nos concitoyens à l’égard de leurs dirigeants politiques.
Le travail d’écriture de la loi nous appartient, n’y renonçons pas.
La parole est à Monsieur François Ruffin, pour soutenir l’amendement numéro cinquante-huit.
Ce texte a donné lieu à deux avis, l’un du Conseil d’État et l’autre de la CNIL, qui tous deux considèrent qu’il apporte des modifications de grande ampleur et qu’il est examiné dans des conditions particulièrement dégradées.
L’article vingt en est le symbole.
Parce que le travail doit être finalisé avant le vingt-cinq mai deux mille dix-huit, il faut se presser et emprunter la voie des ordonnances pour lesquelles le champ de l’habilitation est très large.
Après des ordonnances sur le code du travail, en matière environnementale, et dans le projet de loi pour un État au service d’une société de confiance, on annonce maintenant des ordonnances dans le projet de loi sur l’agriculture.
La cinquième République laisse déjà peu de place au Parlement, faisant de nous une chambre d’enregistrement des désirs du Président et des ministères.
Les ordonnances sont la caricature de ce déséquilibre.
Évidemment, nous refusons cette nouvelle demande d’autorisation à légiférer par ordonnance.
La parole est à Monsieur Jean-Paul Dufrègne, pour soutenir l’amendement numéro cent vingt.
Nous réfutons cette méthode qui découle du manque de lisibilité du projet de loi que nous examinons.
Le Gouvernement a en effet choisi d’adopter une seule loi pour concrétiser le RGPD, transposer la directive, et adapter en conséquence la loi fondatrice du six janvier mille neuf cent soixante-dix-huit.
Il en résulte un empilement de textes, une multiplication des renvois et une superposition des dispositions qui rendent le texte illisible.
Si Madame la garde des sceaux a indiqué que l’ordonnance, prévue pour l’automne au plus tard, serait de nature exclusivement légistique, nous ne pouvons nous satisfaire d’un tel procédé sur un sujet aussi essentiel et transversal.
La parole est à Monsieur Thibault Bazin, pour soutenir l’amendement numéro cent vingt-neuf.
L’amendement a pour objectif de revenir sur l’habilitation afin de permettre un véritable débat au sein des deux assemblées.
Nous sommes très peu nombreux ce soir alors que l’entrée de plain-pied dans la société numérique constitue un enjeu majeur pour nos concitoyens.
Quel est l’avis de la commission ? L’objectif de l’ordonnance est bien, comme l’a rappelé Madame la garde des sceaux, de recodifier la loi de mille neuf cent soixante-dix-huit à droit constant.
Pour avoir étudié le texte en détail, je peux vous assurer qu’il s’agit d’un travail fastidieux, difficile et très technique.
Le Gouvernement l’a déjà amorcé et l’ordonnance devrait être rapidement connue.
Avis défavorable.
Quel est l’avis du Gouvernement ? Je ne reprends pas les éléments que j’ai développés devant vous lors de la discussion générale.
Au regard de l’objectif d’accessibilité et de simplification du droit, nous devons réécrire la loi de mille neuf cent soixante-dix-huit qui est assez compliquée à lire.
Nous le ferons en prenant appui sur le texte que, je l’espère, vous adopterez à l’issue de nos travaux – c’est sur ce dernier que les débats doivent porter.
Une fois que l’ordonnance aura été rédigée, vous aurez l’occasion d’en débattre et de la retravailller.
Cela ne me semble pas soulever de difficulté.
Je répète qu’il s’agit d’une opération à droit constant de pure légistique.
J’émets donc un avis défavorable.
Nous en venons à un amendement portant article additionnel après l’article vingt.
La parole est à Monsieur Éric Bothorel, pour soutenir l’amendement numéro cent cinquante-cinq.
Il s’agit de mettre en cohérence le RGPD et la loi pour une République numérique.
Ceci a été confirmé par les lignes directrices relatives au droit à la portabilité des données qui ont été adoptées par le groupe de travail Article vingt-neuf sur la protection des données.
En outre, le droit européen à la portabilité prévoit des modalités de portabilité plus aisées pour les consommateurs que celles prévues par le droit national.
En conséquence, l’amendement propose de supprimer les dispositions introduites par la loi pour une République numérique, et notamment les articles du code de la consommation, afin d’assurer une application cohérente du droit à la portabilité des données des personnes.
J’espère que cet amendement aura plus de succès que le précédent.
Quel est l’avis de la commission ? Avis favorable sur cet amendement qui contribue à la clarification du droit.
Je suis saisie de deux amendements identiques, numéros trente-deux et quatre-vingt-neuf.
La parole est à Madame Emmanuelle Ménard, pour soutenir l’amendement numéro trente-deux.
Il s’agit d’un amendement rédactionnel visant à substituer au terme d’article celui d’alinéa pour une meilleure compréhension.
La parole est à Madame la rapporteure, pour soutenir l’amendement numéro quatre-vingt-neuf.
Il est défendu.
Nous en venons à un amendement portant article additionnel après l’article vingt-deux.
La parole est à Monsieur Thibault Bazin, pour soutenir l’amendement numéro quatre-vingt-quatre.
Les sanctions administratives, après avoir été considérablement renforcées, sont suffisamment dissuasives.
On peut s’interroger sur le cumul de sanctions administratives et pénales.
Un tel régime de double sanction serait contraire à la jurisprudence de la Cour européenne des droits de l’homme.
Nous vous proposons donc de supprimer les sanctions pénales prévues dans la loi de mille neuf cent soixante-dix-huit.
Quel est l’avis de la commission ? Pour certaines irrégularités, il est préférable de maintenir une voie judiciaire distincte de la voie administrative.
Avis défavorable.
La parole est à Madame Danièle Obono, pour soutenir l’amendement numéro soixante, portant article additionnel après l’article vingt-trois.
Cet amendement précise le concept de neutralité du net qui fait l’objet d’un consensus transpartisan.
Il propose une définition s’appuyant sur des amendements présentés lors de la précédente législature.
La parole est à Monsieur Bruno Bonnell, pour soutenir l’amendement numéro vingt, portant article additionnel après l’article vingt-quatre.
Si le RGPD constitue une avancée au regard de l’opacité actuelle du traitement de notre vie numérique, il n’est qu’une étape.
Il permet à chaque individu de repérer et de piloter le flux de ses données numériques, mais il est muet sur la valeur patrimoniale et morale de ces dernières.
S’il existe un droit des brevets ou des droits d’auteur, il n’y a aucun droit attaché aux données numériques personnelles.
Cet amendement a pour objectif de rendre à tout un chacun ce qui lui appartient : la jouissance des droits moraux sur ses données numériques, une spécificité française.
Chacun aura ainsi le loisir de les léguer à ses héritiers, de les mettre à la disposition librement de la communauté, mais il détiendra surtout une autorité sur son intégrité numérique.
La prise de conscience de la valeur de ces données, qui dépasse la question de leur valeur marchande, est un enjeu culturel clé de notre siècle.
En laissant piller librement nos productions numériques, sans discussion sur leur propriété, nous risquons un nivellement, voire un effacement de la diversité mondiale.
Nombre d’objets et d’images de civilisations disparues désormais protégés au nom de la préservation du patrimoine et exposés dans les vitrines des musées n’ont jamais été pensés ou réalisés par autre chose que les nécessités et les routines du quotidien.
Nous devons considérer que nos données numériques sont du même ordre.
Il faut plutôt réfléchir à un droit d’usage, qui pourrait être partagé avec plusieurs acteurs, ce qui autoriserait la collecte et le traitement des données sous réserve, bien sûr, du respect du droit des individus.
Le cadre du RGPD, dont nous venons de discuter, est assez protecteur en la matière ; il permet de trouver l’équilibre souhaité entre protection et innovation.
Il ne me paraît donc pas opportun d’aller dans cette direction.
Avis défavorable.
Oh non ! Quel est l’avis du Gouvernement ? Avis défavorable également.
Oh non ! Je pourrais m’exprimer plus longuement sur ce sujet, mais ce n’est malheureusement plus l’heure ; peut-être aurons-nous l’occasion de reprendre ce débat en d’autres lieux.
La question que vous posez, monsieur Bonnell, est très complexe.
À ce stade, il me semble globalement plus sage de préserver le cadre juridique équilibré que nous proposons que de s’engager dans la voie d’une patrimonialisation des données.
Je ne suis d’ailleurs pas certaine que cela permettrait, in fine, de protéger davantage les détenteurs de données personnelles.
La parole est à Monsieur Bruno Bonnell.
Je comprends que le présent texte vise à protéger les données personnelles.
Il n’en reste pas moins qu’il faudra se poser les questions – évoquées par de nombreux orateurs au cours de la soirée – qui touchent aux techniques et aux digital natives, véritable évolution de notre civilisation.
Eh oui ! Lorsque mon collègue Éric Bothorel a parlé de la liberté de choisir son moteur de recherche, on s’est reporté à des textes trop simplifiés ou trop complexes.
Lorsque j’ai évoqué le problème des droits patrimoniaux ou moraux, on m’a expliqué que ce n’était pas le moment.
Le vingt et unieme siècle, c’est le corps, l’esprit et les données numériques.
Nous reviendrons évidemment sur ces questions, le cas échéant dans le cadre d’une discussion plus complète.
Maintenez-vous votre amendement, monsieur Bonnell ? Oui, madame la présidente.
Nous avons achevé la discussion des articles du projet de loi.
Je rappelle que la Conférence des présidents a décidé que les explications de vote et le vote, par scrutin public, sur l’ensemble du projet de loi auront lieu le mardi treize février, après les questions au Gouvernement.
La séance est levée.